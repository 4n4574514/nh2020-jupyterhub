# Access Control List for JupyterHub, will be written to a file mounted in
# /etc/jupyterhub/acl/acl.yaml and parsed by custom authenticator logic.
acl.yaml: {}

jupyterhub:
  hub:
    # ref: https://jupyterhub.readthedocs.io/en/stable/reference/services.html#properties-of-a-service
    services:
      grafana:
        # This will make the CHP proxy let /services/grafana route to the
        # grafana service in the k8s namespace, which lets us make use of
        # JupyterHub's HTTPS setup without needing something like nginx-ingress
        # + cert-manager and additional ingress k8s resources.
        url: http://grafana

    extraConfig:
      00-acl-parsing: |
        import os
        from functools import lru_cache

        import yaml

        @lru_cache()
        def _load_acl():
            """
            Load a mounted Access Control List (ACL) from disk.
            
            Note that @lru_cache memoizes this function so it only runs once.
            """
            acl = {}
            path = "/etc/jupyterhub/acl/acl.yaml"
            if os.path.exists(path):
                print(f"Loading Access Control List (ACL) from {path}")
                with open(path) as f:
                    acl = yaml.safe_load(f)
                    for group, usernames in acl.items(): 
                        acl[group] = [username.lower() for username in usernames]
            else:
                print(f"No Access Control List (ACL) at {path}")
            return acl
        
        c.Authenticator.admin_users = _load_acl()["admins"]
        c.Authenticator.whitelist = {
            *_load_acl()["admins"],
            *_load_acl()["instructors"],
            *_load_acl()["participants"]
        }

        # Helper functions for logic in spawner hooks etc that may want to act
        # based on this information.
        @lru_cache()
        def is_admin(username):
            return username in _load_acl()["admins"]
        @lru_cache()
        def is_instructor(username):
            return username in _load_acl()["instructors"]
        @lru_cache()
        def is_participant(username):
            return username in _load_acl()["participants"]


# Reference on the configuration options:
# https://github.com/helm/charts/blob/master/stable/grafana/values.yaml
grafana:
  fullnameOverride: grafana

  # NOTE: We need Recreate when using a persistence PVC. If we use an external
  # database, we can do a RollingUpdate instead.
  deploymentStrategy:
    type: Recreate

  persistence:
    type: pvc
    enabled: true

  service:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/path: "/services/grafana/metrics"

  resources:
    limits:
      cpu: 1
      memory: 1Gi
    requests:
      cpu: 100m
      memory: 1Gi

# Reference on the configuration options:
# https://github.com/helm/charts/blob/master/stable/prometheus/values.yaml
prometheus:
  fullnameOverride: prometheus

  # the actual prometheus server that polls various sources for metrics etc.
  server:
    fullnameOverride: prometheus-server
    enabled: true

    # data retention period
    retention: 90d

    # NOTE: We prefer StatefulSet to be used when using a persistence PVC. If we
    #       use an external database, we can use a Deployment with rolling
    #       updates instead. Until then, we should shut down one pod and then
    #       start up another, which a StatefulSet will do by default and a
    #       Deployment will Recreate as an upgradeStrategy will also do.
    statefulSet:
      enabled: true
    persistentVolume:
      enabled: true

    resources:
      limits:
        cpu: 1
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 1Gi

  # alertmanager is meant to be able to alert using email etc. Grafana can also
  # do this by itself to some degree at least as I understand it.
  alertmanager:
    fullnameOverride: prometheus-alertmanager
    enabled: false

  # kube-state-metrics exports information coming from the kubernetes api-server
  # about the state of kubernetes resources. It can list the state of pods etc.
  #
  # ref: https://github.com/helm/charts/blob/master/stable/prometheus/requirements.yaml
  # ref: https://github.com/helm/charts/tree/master/stable/kube-state-metrics
  kube-state-metrics:
    fullnameOverride: prometheus-kube-state-metrics
  kubeStateMetrics:
    enabled: true

  nodeExporter:
    fullnameOverride: prometheus-node-exporter
    enabled: true
    # NOTE: We want to be able to scrape metrics on all nodes, even GPU nodes
    #       etc.
    tolerations:
      - operator: "Exists"

  # pushgateway is meant to buffer metrics pushed to it from short lived sources
  # and expose them later for prometheus in their place.
  pushgateway:
    fullnameOverride: prometheus-pushgateway
    enabled: false
